Complex Networks Notes

Notation:
sum(i,j,k,sum_expr) is sum from j to k with index i over sum_expr
[A^n] is matrix exponentiation: A to the nth power
A^T is matrix transpose of A



2018-08-28:
A graph G = (V,E) where V:nodes, E:edges,|V|=n,|E| = m

Adjacency matrix:
A:nxn
A_ij = {1 if there exists (j,i) e E
       {0 otherwise
If G is undirected, A_ij = A_ji foreach i,j
Degree of node i is # of edges incident on i
For undirected network/graph, degree of network is:
    -total count of 1s in adjacency matrix:
        sum(i,1,n,sum(i,1,n,A_ij))
density: c = (1/n)sum(1,n,A_i) = (2m/n)
Dense networks: easier to find paths through network but comm btween nodes could interfere more easily
Sparse networks: less contention but finding paths is slower
Find max number of nodes that are directly connected => vertex cover
Find max density (max num edges) => n choose 2 (pick any node, it has n-1 neighbors. Pick another, it has n-2, and so on for all nodes)

Walk: more general than a path
    a series of nodes v_1, v_2, ... , v_i where there exists an edge between v_i,v_i+1 for each i=1...n-1
How many walks of length n are in graph G?
    How many walks of length 2?
        sum(p,1,n,A_ip*A_pj) for each i,j = [A^2]_ij
    How many walks of length 3?
        sum(p,1,n,sum(q,1,n,A_ip*A_pq*A_qj)) i,j = [A^3]_ij
    How many walks of length r?
        [A^r]_ij
    How many cycles of length r that start and end on i
        [A^r]_ii
Tress:
    For any two nodes, there's only one path between
    It's possible to have n-1 edges but fail to have a tree
    Trees are fragile for use with routing: imagine removing one edge from the root to a subtree - that whole subtree is inaccessible!
    However, they are also efficient since there's only one path for each pair of nodes
        Can mitigate the fragility by having nodes remember connections to "siblings"

Directed Networks:
Edges have direction, adjacency matrix is no longer necessarily symmetric
    ex. If our nodes are papers and edges citations
    Cocitation matrix:
        For papers i,j,k:
        i<------k------->j
            c_ij = sum(1,n,k,A_ik*A_jk)
            (Cocitation matrix) C = c_ij foreach(i,j=1...n) = AA^T
    Bibliographic Coupling:
        For papers i,j,k:
        i------->k<-------j
        b_ij = sum(k,1,n,A_ki*A_kj)
        (Bibliographic coupling matrix) B = b_ij foreach(i,j=1...n)
For next time: directed acyclic graphs (DAGs)

2018-08-30:
DAGs
G = (V,E)
Reordering:
V = {v_1,v_2,...} -> v_1',v_2',v_3',...
such that (v_i',v_j') element of E for i<j

DFS: depth-first search
Each node has these atributes:
    -V.pi: parent of V
    -V.visited: been visited or not?
    Extra properties (in addition to the standard DFS things above):
    -V.start: start time of visit of node V
    -V.end: end time of visit of node V
Algorithm:

DFS(G):
    for v in V:
        v.pi = nil
        v.visited = false
        v.start = v.end = {}
    t=0
    for v in V where v.visited==false:
        DFS_VISIT(G,v)
    return nodes (optionally order by v.end desc)
    
DFS_VISIT(G,v):
    t++
    v.start = t
    v.visited = true
    for q where isAdjacent(q,v):
        if q.visited == false:
            q.pi = v
            DFS_VISIT(G,q)
    t++
    v.end = t
            
DFS is O(|V|+|E|) and the sort is at best O(|V|log|V|), so overall complexity depends on whether the graph is dense or sparse (|E| can be O(|V|^2)

Strongly-connected components:
G=(V,E) a directed graph
C a maximal (NOT THE SAME AS MAXIMUM SET) subset of V, foreach v,q elements of C
There is a path v -> q (and q -> v)
In undirected graphs, all connected components are strongly connected

Transpose (of a graph G):
    G^T =(V,E^T)
    E^T = {(v,q) if (q,v) in E}

Algorithm to find strongly-connected components:
SCC(G):
    DFS(G)
    Calculate G^T
    DFS(G^T) picking starting nodes in order by end times set in previous step
    return DFS trees
The set of DFS trees returned is also the set of strongly connected components!

2018-09-04:
Shortest path:
    G=(V,E), v_1,v_2 in V  v_1,v_2 in E w(v_1,v_2) in IR+
    w(v_1,v_2) in IR+
    Optimality principle:
    |-----P------|
    v-----Z------q
      p_1    p_2
      
      w(P) = delta(v,q)
      need to look up proof - proceeds by contradiction
      
Shortest path tree:
    foreach e in E, w(e) = c (all weights are constant c)
    Just do BFS. Each level is another multiple of c (c,2c,3c...)
    ******Shortest-path tree != minimum spanning tree******
    Djikstra's can do this too
    
Shortest-path: Floyd-Warshall
    W:n x n, n = |V|)
    switch(W[i,j]){
        case i=j: 0
        case w(i,j): (v_i,v_j) in E
        else: infinity
    }
    Intermediate Vertex: every node except source and destination
    path P = (v_1,v_2,...,v_k-1,v_k)
    Vertices are numbered 1,2,3,...n
    Consider a subset of the vertices {1,...,k}. Let P be the shortest path between two nodes i,j using only the nodes in {1,...,k} as intermediate nodes
    Two cases: does k appear as an intermediate vertex in P?
        if no: in P->all intermediate vertices are in {1,...,k-1}
                    ->the shortest path using {1,...,k-1} as intermediate nodes is also the shortest path using {1,...,k}
        if yes: k is an intermediate node in P:
            i----k-----j
              P_1  P_2
              P_1,P_2 are shortest paths
               k cannot be in P_1,P_2 or they wouldn't be shortest paths otherwise
               intermediate nodes between i,j must be in {1,...,k-1}
               
    Let d(i,j,k) means "shortest-path weight between i and j using nodes {1,...,k-1}
    Base case:k=0
        d(i,j,0) = W[i,j]
    Inductive case:
        d(i,j,k) = min( d(i,j,k-1), d(i,k,k-1)+d(k,j,k-1) )
    
    Predecessor Matrix:
        PI:n x n
        switch( PI[i,j] ):
          case i=j: NIL
          case no path from i to j: NIL
          else: predecessor of j in the sp (shortest path) from i  
    
    def Print_SP(PI,i,j):
        if i == j:
            Print'i''
            return
        if PI[i,j] == NIL:
            return
        Print_SP(PI,i,PI[i,j])
        Print''j''
        
    Base case like before k=0
    Inductive case: min( PI(i,j,k-1), PI(k,j,k-1) )

    FW(W,n){ #look up the rest online
        d(i,j,0) = W[i,j]
        PI(i,j,0) (like our base case)
        for k in 1...n:
            new matrices d(i,j,k) and PI(i,j,k
            for i in 1...n:
                for j in 1...n:
                    if d(i,j,k-1
                    <incomplete>

*****2018-9-6*****
Knapsack 0-1:
    Set of items A = {a_1,a_2,...,a_n}
    Item a_i have value v_i
    Item a_i has weight w_i
    Knapsack with capacity B
    Problem: Which items maximize the total value but total weight <= B
    Solution looks like: S^* = argmax(S subeset of A) sum(i,a_i in S,,v_i) such that sum(i,a_i in S,,i,w_i) < B
    One can often model NP-Hard problems as ILP problems but the reverse is not generally true
    0-1 Integer Linear Programming (ILP): x_i = 1 if a_i in S^* else 0
    So we want max of sum(i,1,n,x_i*v_i) such that sum(i,1,n,x_i*w_i) <= B
        x_i element of {0,1} (set) which is NOT the same as saying [0,1] (interval)

    Do this with a dynamic programming approach:
    T: n x B
    T[i,J] = *VALUE* of the optimum soln by considering the first i elements in a {a_1,...,a_i} and a knapsack with capacity J
    What are the base cases?
        T[0,J] = 0 for j in 1...B
        T[i,0] = 0 for i
    Now, how to find T[i,J]?
        if w_i > J: T[i-1,J]
        else:
            max(v_i + T[i-1,J-w_i] #if a_i is included
            ,T[i-1,J]) #i not included
    
    def KnapsackDP(A,B):
        T[i,0]=T[0,J]=0 for i in 1..n,J in 1..B
        for i in i..n:
            for J in 1..B:
                if w_i> J:
                    T[i,J] = T[i-1,J]
                else:
                    T[i,J] = max{T[i-1,J], v_i + T[i-1,J-w_i]}
        return T[n,B]
    
    Algorithm above does not give you the list of items, just the best total weight for a given subset
    Introduce something extra to find the list:
    
    def Print_knapsack(A,T,i,J):
        if T[i,J] = v_i + T[i-1,J-w_i]:
            print(A[i])
            Print_knapsack(A,T,i-1,J-w_i)
        else:
            Print_knapsack(A,T,i-1,J)
            
Knapsack 0-1 with Dependencies:
    Use the same variable names as before and add:
    G = (A,E)
    (i,J) in E -> a_i provides its value in the solution only if J is part of the solution
    How do we write an objective function to solve this with ILP? Can't just reuse the one shown before... 
    z_i = 1 if a_i provides a value (all dependencies are satisfied) else 0
    So now our objective function is:
        max(i,1,n,v_i*z_i)
    Constraints:
        z_i <= x_i foreach i
        z_i <= z_J foreach (i,J) in E
        sum(i,1,n,x_i*w_i) <= B
        z_i,x_i in {0,1}
        
2018-09-11:
Maximum Flow:
    Say we have a network with two special nodes:
        S: source
        T: destination
    Edges in this network have capacities
    So the question is: what is the maximum amount of data that can be transmitted by S and accepted by T
    Definition: 
    A flow network is a directed graph
    For each edge (u,v) in E,c(u,v)>=0
        (u,v) in E => (v,u) not in E
        (u,v) not in E => c(u,v) = 0
        two special nodes s,t, s!=t
        For v in V \ {s,t} there exists a path s~v~t

    Def: A flow is a function:
        f: V x V => IR
        f(u,v) == amount of flow through edge (u,v)
        0 <= f(u,v) <= c(u,v)
        sum(v,V,f(u,v)) = sum(v,V,f(v,u)) for u in V \ {s,t}
    Def: value of a flow |f| = sum(v,V,f(s,v)) - sum(v,V,f(v,s))
    
    Linear Programming for max flow:
        Decision variables: f(u,v) foreach u,v in V
        Constraints: 
            c(u,v),E,s,t
            max(sum(v,V,f(s,v) - f(v,s)))
            0 <= f(u,v) <= c(u,v)
            sum(v,V,f(u,v)) = sum(v,V,f(v,u))
        Keep in mind that a single flow that can take multiple paths. It's more like water than packets in that regard. 
    ***ALGORITHM***
    Can solve with Ford-Fulkerson algoirthm
        That one's also good for finding maximum bipartite matching
    def: residual network:
        given a flow network G and a flow f, the residual network G_f:
            same nodes as G
            For (u,v) in E:
                cf(u,v) = c(u,v) - f(u,v) (residual capacity)
            if f(u,v) > 0, add an edge (v,u) in G_f with capacity c=f(u,v).
    def: augmenting path:
        Given a flow network G=(V,E) and a flow f, an augmenting path is a simple path from s to t in G_f
        For augmenting path P, cf(P) is the minimum{(u,v) in P|cf(u,v)}
        f_P(u,v) = cf(P) if (u,v) in P else 0
        f'(u,v) = f(u,v) + f_P(u,v) if (u,v) in E else 0
        
    def FloydFulkerson(G,s,t):
    [f(u,v) = 0 for (u,v) in e]
    while there exists path P from s to t in G_f:
        select a path P from s to t in G-f
        cf(P) = min{cf(u,v) s.t. (u,v) in G_f}
        for (u,v) in P:
            if (u,v) in E:
                (u,v).f = (u,v).f - cf(P)
            else:
                (U,v).f = (u,v).f-G_f(P)
        recalculate G_f
        
    Def: Cut (in a flow network): a partition of V is S and T such that s in S and t in T
    Capacity of a cut (S,T): sum(u,S,sum(v,T,c(u,v))) (capacity of all edges through the cut)
    
    
