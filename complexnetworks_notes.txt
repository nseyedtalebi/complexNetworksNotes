Complex Networks Notes

Notation:
sum(i,j,k,sum_expr) is sum from j to k with index i over sum_expr
[A^n] is matrix exponentiation: A to the nth power
A^T is matrix transpose of A



2018-08-28:
A graph G = (V,E) where V:nodes, E:edges,|V|=n,|E| = m

Adjacency matrix:
A:nxn
A_ij = {1 if there exists (j,i) e E
       {0 otherwise
If G is undirected, A_ij = A_ji foreach i,j
Degree of node i is # of edges incident on i
For undirected network/graph, degree of network is:
    -total count of 1s in adjacency matrix:
        sum(i,1,n,sum(i,1,n,A_ij))
density: c = (1/n)sum(1,n,A_i) = (2m/n)
Dense networks: easier to find paths through network but comm btween nodes could interfere more easily
Sparse networks: less contention but finding paths is slower
Find max number of nodes that are directly connected => vertex cover
Find max density (max num edges) => n choose 2 (pick any node, it has n-1 neighbors. Pick another, it has n-2, and so on for all nodes)

Walk: more general than a path
    a series of nodes v_1, v_2, ... , v_i where there exists an edge between v_i,v_i+1 for each i=1...n-1
How many walks of length n are in graph G?
    How many walks of length 2?
        sum(p,1,n,A_ip*A_pj) for each i,j = [A^2]_ij
    How many walks of length 3?
        sum(p,1,n,sum(q,1,n,A_ip*A_pq*A_qj)) i,j = [A^3]_ij
    How many walks of length r?
        [A^r]_ij
    How many cycles of length r that start and end on i
        [A^r]_ii
Tress:
    For any two nodes, there's only one path between
    It's possible to have n-1 edges but fail to have a tree
    Trees are fragile for use with routing: imagine removing one edge from the root to a subtree - that whole subtree is inaccessible!
    However, they are also efficient since there's only one path for each pair of nodes
        Can mitigate the fragility by having nodes remember connections to "siblings"

Directed Networks:
Edges have direction, adjacency matrix is no longer necessarily symmetric
    ex. If our nodes are papers and edges citations
    Cocitation matrix:
        For papers i,j,k:
        i<------k------->j
            c_ij = sum(1,n,k,A_ik*A_jk)
            (Cocitation matrix) C = c_ij foreach(i,j=1...n) = AA^T
    Bibliographic Coupling:
        For papers i,j,k:
        i------->k<-------j
        b_ij = sum(k,1,n,A_ki*A_kj)
        (Bibliographic coupling matrix) B = b_ij foreach(i,j=1...n)
For next time: directed acyclic graphs (DAGs)

2018-08-30:
DAGs
G = (V,E)
Reordering:
V = {v_1,v_2,...} -> v_1',v_2',v_3',...
such that (v_i',v_j') element of E for i<j

DFS: depth-first search
Each node has these atributes:
    -V.pi: parent of V
    -V.visited: been visited or not?
    Extra properties (in addition to the standard DFS things above):
    -V.start: start time of visit of node V
    -V.end: end time of visit of node V
Algorithm:

DFS(G):
    for v in V:
        v.pi = nil
        v.visited = false
        v.start = v.end = {}
    t=0
    for v in V where v.visited==false:
        DFS_VISIT(G,v)
    return nodes (optionally order by v.end desc)
    
DFS_VISIT(G,v):
    t++
    v.start = t
    v.visited = true
    for q where isAdjacent(q,v):
        if q.visited == false:
            q.pi = v
            DFS_VISIT(G,q)
    t++
    v.end = t
            
DFS is O(|V|+|E|) and the sort is at best O(|V|log|V|), so overall complexity depends on whether the graph is dense or sparse (|E| can be O(|V|^2)

Strongly-connected components:
G=(V,E) a directed graph
C a maximal (NOT THE SAME AS MAXIMUM SET) subset of V, foreach v,q elements of C
There is a path v -> q (and q -> v)
In undirected graphs, all connected components are strongly connected

Transpose (of a graph G):
    G^T =(V,E^T)
    E^T = {(v,q) if (q,v) in E}

Algorithm to find strongly-connected components:
SCC(G):
    DFS(G)
    Calculate G^T
    DFS(G^T) picking starting nodes in order by end times set in previous step
    return DFS trees
The set of DFS trees returned is also the set of strongly connected components!

2018-09-04:
Shortest path:
    G=(V,E), v_1,v_2 in V  v_1,v_2 in E w(v_1,v_2) in IR+
    w(v_1,v_2) in IR+
    Optimality principle:
    |-----P------|
    v-----Z------q
      p_1    p_2
      
      w(P) = delta(v,q)
      need to look up proof - proceeds by contradiction
      
Shortest path tree:
    foreach e in E, w(e) = c (all weights are constant c)
    Just do BFS. Each level is another multiple of c (c,2c,3c...)
    ******Shortest-path tree != minimum spanning tree******
    Djikstra's can do this too
    
Shortest-path: Floyd-Warshall
    W:n x n, n = |V|)
    switch(W[i,j]){
        case i=j: 0
        case w(i,j): (v_i,v_j) in E
        else: infinity
    }
    Intermediate Vertex: every node except source and destination
    path P = (v_1,v_2,...,v_k-1,v_k)
    Vertices are numbered 1,2,3,...n
    Consider a subset of the vertices {1,...,k}. Let P be the shortest path between two nodes i,j using only the nodes in {1,...,k} as intermediate nodes
    Two cases: does k appear as an intermediate vertex in P?
        if no: in P->all intermediate vertices are in {1,...,k-1}
                    ->the shortest path using {1,...,k-1} as intermediate nodes is also the shortest path using {1,...,k}
        if yes: k is an intermediate node in P:
            i----k-----j
              P_1  P_2
              P_1,P_2 are shortest paths
               k cannot be in P_1,P_2 or they wouldn't be shortest paths otherwise
               intermediate nodes between i,j must be in {1,...,k-1}
               
    Let d(i,j,k) means "shortest-path weight between i and j using nodes {1,...,k-1}
    Base case:k=0
        d(i,j,0) = W[i,j]
    Inductive case:
        d(i,j,k) = min( d(i,j,k-1), d(i,k,k-1)+d(k,j,k-1) )
    
    Predecessor Matrix:
        PI:n x n
        switch( PI[i,j] ):
          case i=j: NIL
          case no path from i to j: NIL
          else: predecessor of j in the sp (shortest path) from i  
    
    def Print_SP(PI,i,j):
        if i == j:
            Print'i''
            return
        if PI[i,j] == NIL:
            return
        Print_SP(PI,i,PI[i,j])
        Print''j''
        
    Base case like before k=0
    Inductive case: min( PI(i,j,k-1), PI(k,j,k-1) )

    FW(W,n){ #look up the rest online
        d(i,j,0) = W[i,j]
        PI(i,j,0) (like our base case)
        for k in 1...n:
            new matrices d(i,j,k) and PI(i,j,k
            for i in 1...n:
                for j in 1...n:
                    if d(i,j,k-1
                    <incomplete>

*****2018-9-6*****
Knapsack 0-1:
    Set of items A = {a_1,a_2,...,a_n}
    Item a_i have value v_i
    Item a_i has weight w_i
    Knapsack with capacity B
    Problem: Which items maximize the total value but total weight <= B
    Solution looks like: S^* = argmax(S subeset of A) sum(i,a_i in S,,v_i) such that sum(i,a_i in S,,i,w_i) < B
    One can often model NP-Hard problems as ILP problems but the reverse is not generally true
    0-1 Integer Linear Programming (ILP): x_i = 1 if a_i in S^* else 0
    So we want max of sum(i,1,n,x_i*v_i) such that sum(i,1,n,x_i*w_i) <= B
        x_i element of {0,1} (set) which is NOT the same as saying [0,1] (interval)

    Do this with a dynamic programming approach:
    T: n x B
    T[i,J] = *VALUE* of the optimum soln by considering the first i elements in a {a_1,...,a_i} and a knapsack with capacity J
    What are the base cases?
        T[0,J] = 0 for j in 1...B
        T[i,0] = 0 for i
    Now, how to find T[i,J]?
        if w_i > J: T[i-1,J]
        else:
            max(v_i + T[i-1,J-w_i] #if a_i is included
            ,T[i-1,J]) #i not included
    
    def KnapsackDP(A,B):
        T[i,0]=T[0,J]=0 for i in 1..n,J in 1..B
        for i in i..n:
            for J in 1..B:
                if w_i> J:
                    T[i,J] = T[i-1,J]
                else:
                    T[i,J] = max{T[i-1,J], v_i + T[i-1,J-w_i]}
        return T[n,B]
    
    Algorithm above does not give you the list of items, just the best total weight for a given subset
    Introduce something extra to find the list:
    
    def Print_knapsack(A,T,i,J):
        if T[i,J] = v_i + T[i-1,J-w_i]:
            print(A[i])
            Print_knapsack(A,T,i-1,J-w_i)
        else:
            Print_knapsack(A,T,i-1,J)
            
Knapsack 0-1 with Dependencies:
    Use the same variable names as before and add:
    G = (A,E)
    (i,J) in E -> a_i provides its value in the solution only if J is part of the solution
    How do we write an objective function to solve this with ILP? Can't just reuse the one shown before... 
    z_i = 1 if a_i provides a value (all dependencies are satisfied) else 0
    So now our objective function is:
        max(i,1,n,v_i*z_i)
    Constraints:
        z_i <= x_i foreach i
        z_i <= z_J foreach (i,J) in E
        sum(i,1,n,x_i*w_i) <= B
        z_i,x_i in {0,1}
        
2018-09-11:
Maximum Flow:
    Say we have a network with two special nodes:
        S: source
        T: destination
    Edges in this network have capacities
    So the question is: what is the maximum amount of data that can be transmitted by S and accepted by T
    Definition: 
    A flow network is a directed graph
    For each edge (u,v) in E,c(u,v)>=0
        (u,v) in E => (v,u) not in E
        (u,v) not in E => c(u,v) = 0
        two special nodes s,t, s!=t
        For v in V \ {s,t} there exists a path s~v~t

    Def: A flow is a function:
        f: V x V => IR
        f(u,v) == amount of flow through edge (u,v)
        0 <= f(u,v) <= c(u,v)
        sum(v,V,f(u,v)) = sum(v,V,f(v,u)) for u in V \ {s,t}
    Def: value of a flow |f| = sum(v,V,f(s,v)) - sum(v,V,f(v,s))
    
    Linear Programming for max flow:
        Decision variables: f(u,v) foreach u,v in V
        Constraints: 
            c(u,v),E,s,t
            max(sum(v,V,f(s,v) - f(v,s)))
            0 <= f(u,v) <= c(u,v)
            sum(v,V,f(u,v)) = sum(v,V,f(v,u))
        Keep in mind that a single flow that can take multiple paths. It's more like water than packets in that regard. 
    ***ALGORITHM***
    Can solve with Ford-Fulkerson algoirthm
        That one's also good for finding maximum bipartite matching
    def: residual network:
        given a flow network G and a flow f, the residual network G_f:
            same nodes as G
            For (u,v) in E:
                cf(u,v) = c(u,v) - f(u,v) (residual capacity)
            if f(u,v) > 0, add an edge (v,u) in G_f with capacity c=f(u,v).
    def: augmenting path:
        Given a flow network G=(V,E) and a flow f, an augmenting path is a simple path from s to t in G_f
        For augmenting path P, cf(P) is the minimum{(u,v) in P|cf(u,v)}
        f_P(u,v) = cf(P) if (u,v) in P else 0
        f'(u,v) = f(u,v) + f_P(u,v) if (u,v) in E else 0
        
    def FloydFulkerson(G,s,t):
    [f(u,v) = 0 for (u,v) in e]
    while there exists path P from s to t in G_f:
        select a path P from s to t in G-f
        cf(P) = min{cf(u,v) s.t. (u,v) in G_f}
        for (u,v) in P:
            if (u,v) in E:
                (u,v).f = (u,v).f - cf(P)
            else:
                (U,v).f = (u,v).f-G_f(P)
        recalculate G_f
        
    Def: Cut (in a flow network): a partition of V is S and T such that s in S and t in T
    Capacity of a cut (S,T): sum(u,S,sum(v,T,c(u,v))) (capacity of all edges through the cut)
    
2018-9-13: Guest lecture on Stochastic Geometry
****need to look a lot up, I lacked statistical knowledge to really follow along*****
What is a spatial point process?
    -Fill in later
    For these procs, we only care about number of points and where they are
Binomial point process (BPP): superposition of N independent uniformly distributed points on the set A
    "What's the probability that we have k points in a given subset of A (looks like the a box since we are considering a subset of 2-d real numbers)
Void probability: look it up
How to test equivalence?
    If they have same void probabilities (look up)
Stationary point process: distr is invariant w.r.t. translations
    Cannot be defined on a subset of R^2 - why not though??
Stationary Poisson Point Process (PPP):
    most widely used model for spatial location of nodes
    no dependence between node locations
    Can be completely characterized by a single number lambda, the density
    Density is the expectation of the # pts of any set A

Lemma: A is a subset of R^2. Conditioned on the number of points phi(A), the points are independently and uniformly distributed in the set A, i e the points form a BPP
How to simulate?
    # point in A is poisson rnd var with mean lambda
Distance properties:
    First contact distribtion: the CCDF of the dist of the nearest point of the process from the origin denoted by D is P(D>=r) = exp(-\lambda\pir^2)
N-th closest point? Look up
Campbell's theorem (look up)
Example: apply Cambell's to find mean and variance of interference (like w cell phones or wifi)
    Interference at location y in R^2 is I(y) = sum(x,x in \pih,l(x-y)) where l(x) is the path loss function
Lemma: probability generating functional (PGFL):
    Let \phi be a PPP of density \lambda and f(x): R^2 -> [0,1] (incomplete)
Transformation of PPP: Independent thinning
    let \phi be a ppp of density \lambda
    1. a node x in \phi is colored red with probability p and blue with probability 1-p
    2. (more steps)
Matern hard-core process: dependent thinning

Reduced Palm probability:notion of a typical point i.e. conditioning on the existence of an ode at a particulr location
    What's the nearest-neighbor distribution function?
    Can be interpreted as a spatial average
    Slivnyak thm: reduced palm distr of a PPP equals the original distribution

Applications
Cellular networks
    Interference is the main challence in cell networks
        SINR (signal+interference noise ratio) more important than SNR (signal to noise ratio)
        BS cooperation and other interference-suppression techniques require good models for other-cell interference
    Networks are becoming unplanned and decentralized
        Picocells placed strategically
        femotcells/relays being placed randomly
        BS deployments increasingly driven by capacity needs rather than coverage needs
    Proposed model: PPP base stations
        advantages:
            non-uniform cell sizes
            tractable? Yes, but usu reqs numerical soln
        disadvantages:
            base stations might get very close
    Use first contact distribution
    condition on the dist to nearest BS r
        find probability that SINR is >= some \theta
    Turns out that adding base stations does not increase coverage probability (bc. of interference!)
    Often have to solve numerically
    Frequency reuse:
        frequency planning necessary to increase coverage (bc interference, remember??)
        Model as PPP with random allocation of freq bands
        Corresponds to a thinning of a PPP \phi
    Coverage vs (ergodic) rate: coverage increases with \delta (# of freq bands) while average rate descreases with \delta
Heterogeneous Networks:
    System model:
        k tier network
        the bs locations in tier i are modeled by a ppp \phi i
        all tiers transmit in same freq band
    Max SIR model:
        A mobile user can connect to a BS of any tier provided taht the SIR constraint is satisfied: to conect to a bs of tier i, the SIR should be greater than \theta_iss
    
2018-09-17
Green communication systems for smart cities

REvisit - shortest path problem: single-source, all pairs
Optimality priciple: If P(u,v) is a shortest path from node u to node v, then
Restricted shortest path: each edge has a weight and an additional metric c(e)
	The goal is to determine the least-weight path such that the sum of the additional metric is bounded by a predefined constant C
NP-Hard, proof by reduction from partition or knapsack
Other variants: bottleneck shortest-path, balanced shortest-path, minimum-deviation shortest path

Smart and Connected Community (SCC)
	Why? Social and environmental sustainability
	Connectivity between devices and to the internet is crucial
	How to support connectivity in rural area without lots of expensive infrastructure? 
	Issues with SCC:
		economic: not cost-effective to invest in dedicated infrastructure, High operating costs
		Sustainability: ICT devices produce lots of CO2, spectrum scarcity
	Feasible solution?
		Use a network of ixed or mobile cyber-physical devices connected via wireless links
		No additional infrastructure cost
	Current wireless options:
		short-range like bluetooth, wifi in unlicensed bands (2.4, 5GHz)
		Long-range cellular technologies like 3/4G, GSM, LTE, LTE-A operating in licensed spectrum
		These are not an effective solution because they are not energy-efficient, cost-effective, and can't provide QoS guarntees
	How about using different parts of the spectrum for different applications?
	For example: low bit rate, low power for VoIP and high bitrate and high power for video
	If we use the spectrum intelligently by matching the EM characteristics to the application, we can solve the problems with current offerings

Dynamic Spectrum Access (DSA)
	Allows wireless devices to opportunistically access unoccupied bands (whitespace or spectrum holes), originally licensed on condition of non-interference to the primary licensees
	Empty channels within a certain spectrum band is liable to be accessed for data communictions.
	Advantages:
		Break away from the policy constraint
		overcome problem of over/underprovisioning
		Allowed by (or in memoranda) by US FCC in:
			TV band (54-698 MHz)
			LTE Band (900 Mhz, 1700-2100 MHz)
			CBRS band
			ISM band
	Optimal Band Selection
	Objective: determine optimal TTL constrained energ-efficient (TcE) path for any given message m<S,D,L,T> that maximizes energy efficiency and meets the TTL
	NP-Hard: reduction from Restricted Shortest Path (RSP) problem
	Soln 1: select a path p(u,v) bt selecting a locally optimal band at each node in the network
	Soln 2: Select a path p(u,v) by selecting the best homogeneous bank at each node in the network
	Neither is optimal!
	Proposed TcE solution: use dynamic programming
	a combination of Floyd-Warshall alg and DP solution of the knapsack problem
	Use 3-D adjacency matrix that includes info about reachability w.r.t. the extra constraint
	If path P is an energy-efficient path between i and j with some intrmediate node k, the paths from i to k and from k to j are also energy-efficient by the optimality principle
	
proposed TcE algorithm:
	1. Init matrix W^(0,t) to A[i,j,k]
		Uses a combined metric H = \beta*w^(j)_ij + (1-\beta)*w^(j)_ij
	2. TcE path via band selection
		Pseudopolynomial run time
DSA enabled architecture for SCCs: only suitable for decision-making with non-real-time deadlines
Optimal TcE path algorithm: pseudopolynomial dynamic programming alg
Can design a poly-time approx alg or suitable heuristic?
What if DSA is a time-varying graph? There are soltions for that too

2018-09-20
Multicommodity Flow Problem
	Flow network G = (V,E)
	Edge capacity c(u,v) (u,v) in E
	k demand (s_i,t_i,d_i): src s_i, dest t_i, demand d_i, s_i, t_i in V
	f_i(u,v):fraction of flow i=1,...,k that goes through edge (u,v) in E
	f_i(u,v) in [0,1]
	Send a unit of flow over edge (u,v), you pay a cost \delta(u,v). Could be different for different edges
	Objective: route all of the demand from source to destination while minimizing the cost

LP Formulation
	We want to minimize the cost. Start with one flow:
	Cost for demand i: sum((u,v),V,sum(i,1..k,f_i(u,v)*d_i*\delta(u,v)))
	sum(v,V,f_i(u,v)) = sum(v,V,f_i(v,u)) for u,i in V\{s_i,t_i},1..k
	0 <= sum(i,1..k,f_i(u,v)*d_i) <= c(u,v)
	sum(v,V,f_i(s_i,v)) - sum(v,V,f_i(v,s_i)) = 1
	sum(v,V,f_i(v,t_i)) - sum(v,V,f_i(t_i,v)) = 1
Potential variants (constraints except objective remain the same unless otherwise noted)
	For each path per flow => f_i(u,v) in {0,1}
	Utilization of (u,v) in E:
		U(u,v) = sum(i,1..k,f_i(u,v)*d_i) / c(u,v)
		min sum((u,v),E,U(u,v))
	Max flow: max(sum(i,1..k,d_i))
	
Max Bipartite Matching
	h_1 people,h_2 tasks
	for each task there are some people tht complete the task
	Each person can complete only one task
	We want ot assign people to tasks to maximize the number of tasks completed
	Bipartite graph G = (L \cup R,E)
	L: set of people
	R: set of tasks
	L and R disjoint
	E \subset L x R
	(u,v) \in E, u \in L, v \in R
	Person u can complete task v
	We are looking for a matching M \subset E \for v \in L \cup R \exists at most one edge in M incident to V
	Matching can be maximal: cannot be extended
	Maximum matching: maximum cardinality
	How to find max? Flow network
	
Use Flow Network to Find Maximal Bipartite Matching:
directed edges from L to R
two special nodes s,t
add edges (s,v) \for v \in L
add edges (v,T) \for v \in R
Set capacities of all edges to 1
Use existing algs for flow networks

2018-09-25:
How do we determine which nodes in a network are "important" (ofc varies on application)?
One way: centrality metrics
	Degree Centrality: Distribution of degree: D(x) = # of nodes with degree x / total # of nodes
	In undirected network, avg degree is 2m / n for a given G=(V,E) and m = |E| and n = |V|

	Eigenvector Centrality: importance of node is proportional to the importance of its neighbors
	iterative algorithm
	x(0) = 1 for each node
	x_i(1) = sum(j,1..n,t_ij*x_j(0))
	x_t(t) = A^t*x(0) where A is the adjacency matrix
Recap of Eigenvectors and Eigenvalues:
	Given a matrix A:n x n,a value \lambda is an eigenvalue for t if \exists a vector v s.t. A*v = \lambda*v, v nonzero
	(A - \lambda*I)v = 0 where I is the n x n identity matrix
	p(\lambda) = det(A - \lambda I)
	eigenvalues are the roots of p(\lambda)
	The set of eigenvectors of t are linearly independent:
	(a vector over all nodes in G) x(0) = sum(i,1..n,c_i*v_i)
	x(t) = A^t * sum(i,1..n,c_i*v_i)
	= sum(i,1..n,c_i * \lambda_i^t * v_i)
	= \lambda_1^t * sum(i,1..n,c_i * [\lambda_i / \lambda_1]^t * v_i)
	x(t) = \lambda_1^t * c_1 * v_1 + sum(i,2..n,c_i * [\lambda_i / \lambda_1]^t * v_i
	The bracketed term tends to zero as t grows, so first term is most important
	x_i = (1 / \lambda) * sum(j,1..n,A_ij * x_j)
	So eigenvector centrality: x_i / d_i

Closeness Centrality
	d_ij is the shortest-path distance from i to j
	mean distance e_i = (1/n) * sum(j,1..n,d_ij)
	closeness centrality: c_i = 1 / e_i = n / (sum(j,1..n,d_ij))
	If the graph has more than one connected component, then we define the closeness centrality over each component

Betweenness Centrality: 
	Say we have a communication network in which nodes generate traffic
	Traffic is sent to all nodes in the network
	Betweenness centrality tells us how much traffic goes through a certain node
	=> it's proportional to the number of shortest paths through that node
  More formally:
	(n^i)_(s,t) = 1 if i is in the shortest path between S and T
		       = 0 otherwise
	x_i = sum(s and t, V,n^i_(s,t)
	Maximum value: n^2 - (n-1) where n = |V|
	Minimum value: (n-1) + (n-1) + 1 = 2n - 1
	f_st = number of shortest-paths between s and t
	x_i = sum(s and t, V, n^i_(s,t) / f_st)

2018-09-27:
Centrality metrics in Directed Networks
	A * x = \lambda_1 * x
	outdegree: xA=\lambda*x (left eigenvectors)
	indegree: Ax = \lambda * x (right eigenvectors)
	The nodes that have nonzero eigenvectors must either be part of a strongly-connected component of the graph or have an in-edge from a strongly-connected component

Katz centrality:
	Each node has a minimum centrality \Beta
	x_i = \xi * sum(j,1..n,A_ij * x_j + \Beta), \xi , \Beta > 0
	x = \xi * A*x + \Beta*@ where @ is the identity vector with dimension n
	=(I - \xi*A)^-1
	\xi < \lambda_1 where \lambda_1 is the leading right eigenvalue.

Page Rank:
	x_i = \xi * sum(j,1..n,A_ij * (x_j / k_j^out) + \Beta where k_j^out is the outdegree of k_j
	x = \xi * A * D^-1 * x + \Beta*@
	...
	x = D(D-\xi * A)^-1 * @
	Setting \xi = 0.85 to start gives good results

Optimization over matroids (Whitney, 1935)
Definitions:
	*Independence system: a pair (U,s) where U is the universe set, |U| < \infinity and S \subset 2^U or S is a subset of the  powerset of U such that:
		S contains the empty element
		if x \subset y, y \in S => x \in S
		e.g. U = {v_1,v_2,...,v_n}
		U contains the subsets of U that are linearly independent
	*A basis B is a maximal independent subset of U
	i.e. B \in S, x \in U\B, B+x \notin S
	*A modular set function is a function  f:2^U -> \mathbb{R} is modular for each x \subset U, f(x) = sum(x,X,f({x}))
	e.g. if we have a set of edges, a modular set function might return the sum of the weight of the edges in the input set
	*Given X \subset U, the *rank* of X = max{|y| s.t. y \subset X, y \in S}
	*A *Matroid* M = (U,S) is an independent system s.t. if x,y \in S, and |x| > |y| then:
	\exists x \in X\Y s.t. x+y \in S
	In a matroid all basis have the same cardinality
PROBLEM: given a matroid M = (U,S) and a modular function f: 2^U -> \mathbb{R}, find the basis with minimum cost. Usually S is *not* given and is usually HUGE.
GREEDY ALGORITHM SOLUTION:
X = {}
Sort U = {u_1,u_2,...,u_n} s.t. f(u_1) <= f(u_2) <= ... <= f(u_n)
for i in 1..n:
	if x+u_i \in S: #can add to the set, calculate the rank, see if it changes
		x = x U {u_i}
	return x
The algorithm works no matter the context. Very general and powerful!
How do we use it? The goal is to prove that our problem can be represented by a matroid so we can use the generalized greedy algorithm.

Problem: Given an undirected graph G = (V,E) and a weight function w:E->\mathbb{R}, find a subset Q of the edges s.t. foreach vertex v \in V, there exists (v,u)\in W and W(Q) is minimum. In other words, we want a subset of the edges with minimum weight, or the *minimum spanning tree*

Kruskal's algorithm:
	Q = {}
	Sort edges by increasing weight
	for i in 1..m:
		if Q U {e_i} does not create a cycle, add the edge to Q

The Generalized greedy algorithm finds an optimum soltuion iff it is a matroid
For next class: prove that min. spanning tree is a matroid
For my own edification: look up Prim's algorithm. Is it connected to matroids somehow?

2018-10-02
Proof that min spanning tree is a matroid:
	(U,S_G), G = (V,E)
	U = E
	S_G \subset 2^U set that contains all subsets of edges that do not create a cycle
	{} \in S_G
	Given X \subset Y \subset 2^U, if Y \in S_G then X \in S_G by contradiction
Matroid:
	X,Y \in S_G, s.t. |X| < |Y| => there exists y in Y such that x+y in S_G
	Split into cases:
	1. if exists y in Y\X s.t. y=(u,v) s.t. u or v are not spanned by an edge in X
		=> x+y in S_G
	2.Otherwise, all nodes spanned by Y are also spanned by X
		we know Y,X is a forest of k_y,k_x trees
		2.1. If there exits an edge Y in Y\X, y = (u,v) s.t. u and v belong to different trees in X
	=>x+y in S_G
		2.2 x,y span the same set of nodes and for each edge (u,v) in y, u and v belong to the same tree in X
	if this were true, X and Y would have the same cardinality. This contradicts the intial assumption that |X| < |Y|

Activity selection problem
	Set of activites A = {a_1,a_2,...,a_n}. Activity a_i has start time t_i and end time e_i and [s_i,e_i)
	Two activities overlap a_i,a_j overlap
Problem: find the maximum number of activities that can be scheduled without overlap
Solution (that isn't exponential): order activities by end time, pick in order so that we don't have overlap
Is this a matroid? Try to prove it:
	(A,S_A) where A is set of activity, S_A is all subsets of A containing non-overlapping activities
	As before, first show that it is an independent system
	1. empty set in S_A -> trivially true, no overlap possible in empty set
	2. given X subset Y, if Y in S_A, then X in S_A
	Matroid: X,Y in S_A, |X| < |Y| => there exists y in Y s.t. X+y in S_A

Submodular functions
	Modular functions: proportional returns
	Submodular functions: diminishing returns
	Def: A function f: 2^U -> \mathbb{R} is submodular if for each A subset B subset U, and e in U\B:
		f(A+e)-f(A) >= f(B+e)-f(A)
	Equivalently, for each A,B subset U:
		f(A union B)+f(A intersect B) <= f(A) + f(B)

2018-10-04
Optimization of submodular functions
	see above defs
	Def: a function f: 2^U -> \mathbb{R} is monotone if for each A subset B subset U, f(A) <= f(B)
Examples of submodular functions:
	weighted average
rank functions of matroids
	given a matroid M = (U,S)
	Given V subet of U:
	f(V) = max{|Q| s.t. Q subset V and Q in S}
More examples of submodular functions
	Cut capacity functions in a graph
		G = (V,E)
		c: E -> |R+
		A cut is S subset V, the boundary of which is: \delta S {(u,v) s.t. (u,v) in E and u in S and v in V\S}
		f(S) = sum((u,v),\delta S,c(u,v))
		f({}) != f(V)
properties:
	linear combination: given n submodular functions f_1,f_2,...,f_n and \xi_1,...,\xi_n in |R+, then we can say f(S) = sum(i,n,\xi_i*f_i(S)
	f is submodular iff -f is supermodular
	truncation: given a submodular function g, f(S) = min{g(S),c} for each c} is also submodular
	If f is submodular, concanve function \phi, \phi(f(S))
Minimization of submodular function
	problem: given a submodulr function f:2^U -> |R+
	Find a set S^* subset U s.t. foreach Q subset U, f(S^*) <= f(Q)
	Def: given a function f{0,1}^N -> |R+, that is: all possible vectors of length N with either zero or one
	f^L[0,1]^N -> |R+ f^L(x) = sum(i,0..n,\lambda_i * f(S_i))
	{} = S_0 C S_1 C S_2...C S_n, sum(i,1..n,\lambda_i * |I_si) = x, \lambda_i >=0
	f^L is convex iff f is submodular
	a min for f^L could be found

2018-10-09
Submodular maximization
	NP-HARD
	Given a submodular function f:2^U -> |R, we want to find:
	max(f(S)) where S subset U s.t. |S| <= k
	(can also include a constraint like sum(x,x in S,w(x)) <= B)
	if f({}) = 0 then f is monotone
	solve with greedy algorithm

def GreedySubmodMax(f,U,k):
	S0 = {}
	for i in 1..k:
		v = argmax(v in U\S,f(S[i-1]+v)-f(S[i-1]))
		S[i] = S[i-1] + v

Theorem (Niemhouser '78):
	f(s_k)>= 1 - (1/e) * max(s,|s|<=k ^ s subset U,f(s))
Theorem, Krause 2005:
	Modular weight function w:2^U -> |R
	given S subset U, w(S) = sum(x,x in S,w(x))
	f(s_k) >= (1 - 1/e) * 0.5 *  max(s,|s|<=k ^ s subset U,f(s))
	Can use this to find approx solution for Knapsack 0-1

Random Graphs
	Erdos-Renyi model:
	  fix two parameters
	    number of nodes n
	    probability p in [0,1] of having an edge between two nodes
	    probability of a given graph G with n nodes and m edges:
	      P(G) = p^m(1-P)^((n choose 2)-m)
	  Expected # of graphs with m edges <m>:
	    number of graphs with m edges ((n choose 2) choose m)
	    P(m) = ((n choose 2) choose m)*p^m*(1-p)^((nC2 - m))
	    <m> = sum(m,0..nC2,m*P(m) = nC2 * P
	  Mean degree <d> of a vertex:
	    <k> = 2*m/n = 2<m>/n = (2/n)*(nC2 * p) = (n-1)p
	  Degree Distribution
	    Given a set of k vertices, probability that a node is connected to these vertices is:
	  	p^k(1-p)^(n-1-k)
	    All possible set of vertices without the node itself:
		(n-1)Ck
	    Thus, P(d=k) = (n-1Ck)p^k(1-p)^(n-1-k)
	  Consider:
	    n->inf
	    mean degree is constant
	    <k> = c = (n-1)*p
	    p = c/(n-1)
	    ln((1-p)^(n-1-k)) = (n-1-k)ln(1-p)
	    Use Taylor approx for RHS:
		if log(1-x) = -sum(n,1..inf,x^n/n) then log(1-(c/n-1)) = -c/(n-1)
	    sub in Taylor approx to RHS to get:
		=(n-1-k)*c/(n-1)=-c
	    (1-p)^(n-1-k) approx equal to e^-c
	    Recall we have P(d=k) = (n-1C2)*p^k(1-p)^(n-1-k) (binomial distribution)
	    now, sub our approximation into the expression above to get:
		=(n-1C2)*p^k*e^-c (Poisson distribution)

2018-10-11
Giant component
n,p as defined in previous section on Random Graphs
	p=0 no edge,n components
	p=1 n(n-1)/2, 1 component, size is n
	giant=component size grows with the size of the network
	degree constant c: p=c/(n-1)
	Let m be the average fraction of verticies that do not belong to the GC (giant component).
vertex i does not belong to the GC if foreach J if:
	1)i is not connected to J OR
	2)i connected to J and J is not in the GC
	u = (1-p + up)^(n-1)
	  = (1-p(1-u))^(n-1)
	  = (1- (c/(n-1))(1-u))^(n-1) = RHS
    ln u  = ln(RHS)
	  = (n-1)ln(1- (c/(n-1))(1-u))
	  use Taylor approx. for ln(1-x) again on RHS to get rid of ln then simplify
        u = e^-c(1-u)
	It is hard to find a closed-form solution for the above equation but we can use graphical techniques like this:
	S = fraction of nodes in the GC
	S = 1-u
	S = 1-e^(-cS)
	y = 1-e^-(cS)
	Can use to find the size of the smaller components, distribution of smaller components
	Diameter d:
	d = ln(n) / ln(c)

Degree distribution
	D(x) = # of nodes with degree x / total number of nodes
	ln(D(x)) = e^(-2*ln(x)+c)
	D(x) = e^(-2*ln(x)+c) = e^(ln(x^-2)+c)
	     = e^ln(x^-2)*e^c*c
	D(x) = x^-2 * c
	Look up: Scale-free networks
Cumulative Degree Distribution:
	|P(x >= k) = sum(r,k..inf,D(r))
	approx equal to: c* integral(k,inf,r^-\xi * dr)
	eval intgral and simplify to get:
	c/(\xi - 1) * k^-(\xi - 1)
Preferential attachment:
	Happens when you have networks that grow over time
		-citation network
		-Internet
		-WWW
	First model (Pzime '60) citation networks
	Nodes are papers
	A new papers cites on average c existing papers
	A new paper cite an existing paper with a probability proportional to its in-degree plus a small constant
	Intuitively, you end up with a few papers that get tons of citations and many with few or no citations. "Rich get richer"
	Berebesi-Albert Model ('90)
		-undirected network
		-nodes are added one by one
		 -each node adds c edges
		prob. of connecting a new node to node i (degree d_i):
		P_i = d_i / sum(J,V,d_J)
		|P(d_i = k) = k^-3

2018-10-16
Interference graph - nodes are transceivers, edges link pairs of nodes that can't communicate at the same time. That is, if they both try to talk at the same time, they will interfere.
Maximum independent set
  Def: given an undirected graph G = (V,E), a set of verticies S \subseteq V is independent if there are no adjacent nodes in the set. Alternatively, {\forall u,v \in S:(u,v) \notin E}
  Def An independent set S \subseteq V is maximal if \forall V\S, S\cup {v} is not independent
  Def Maximum independent set max|S| S\subseteq V s.t. S is independent
  This problem is NP-HARD
  Try an Integer Linear Programming approach (ILP):
  x_i = 1 if node i is in selected set or 0 otherwise
  Objective: maximize sum of x_i
  One constraint for each edge: x_i+x_j <=1 foreach (i,j) \in E
  Heuristic Algorithm:
    S = {}
    while G is not empty:
      pick any node v
      S = S \cup {v}
      Remove v from G with all its neighbors (edges and other nodes it's connected to and all of the edges that those nodes touch.i.e. nodes one hop away include all edges that any of these nodes touch)
  Note that this heuristic is terrible when the graph is a star.  Optimal soln in that case is n-1 but this algorithm would return 1
  We can improve upon it by choosing a v from G with minimum degree
  Theorem: The algorithm above returns an idependent set S such that |S| >= n/(\delta + 1) where \delta is the max degree of a node in G
  Proof: we want to find a bound for V \ S
  A node is in V\S if it was a neighbor of a selected node
  \forall v \in S the max number of rmoved nodes is at most \delta
  |V/S| <= \delta |S|
  |S| + |V/S| = n
  n - |S| <= \delta |S|
  n <= |S|(1 + \delta)

2018-10-18
More on optimization problems
Vertex Cover
\forall v \in V, v is either a clusterhead or in direct communication with a clusterhead
Def: Given G = (V,E) a vertex cover is a set s \subseteq V st \forall (u,v) \in E: u \in S or V \in S

ILP
Objective: find minimal vertex cover S
Constraints: we have x_i where i=0...|V|, where x_1=1 if v_i \in S or 0 otherewise
x_i+x_j>=1 \forall (i,j) \in E
x_i = {0,1}

A simple algorithm: Pick a node that has an uncovered edge and add it to S. Repeat until finished.

A better algorithm:
def VertexCover(G):
  S = {}
  while E != 0:
    pick any (u,v) \in E
    S = {u,v} \cup S
    delete all edges incident to u and v
  return S

Thm: The algorithm above returns a vertex cover
Proof: An edge is removed only if at least one of the endpoints is in S, so it is not possible to have an uncovered edge when VertexCover() terminates.
Thm: The set S returned by the algorithm is such that |S| <= 2 * optimal_solution
Proof: The algorithm returns a maximal matching if we pick k edges in the while loop
|S| = 2k
Consider any vertex cover including the optimum: should have at least k vertices
This implies that |optimum| >= k

LP-Relaxation:
  x_i \in [0,1] instead of x_1 \in {0,1} (interval instead of two discrete points]
  Poly time
  Round each x_i to either 1 or 0 depending on some predefined criteria
  
Set Cover
Def: Given a universe set U = {1,...,n}
S \subseteq 2^U s.t. union(c,S,c) = U
Problem: minimize |c| such that c \subseteq S and union(c,S,c) = U
ILP:
  x_i = 1 if subset 1 is selected
  y_ij = 1 if subset i contains element j
  minimize sum(i,1...m,x_i)
  Constraint: sum(i,1...m,y_ij x_i) >= 1 \forall j \in U
Approx. algorithm:
C = {}
I = {}
while(I != U):
  select c \in S
  C = C + c
  I = I \cup c
  S = S - c
return C

improvement: select c \in S s.t. c maximizes c \cap |U/I|
Is it always optimal? NO!
consider: U = {1,...,7}
S = {{1,2,3,4,5},{1,2,7},{3,4,5,6}}
It will pick the first subset even though it isn't optimal because this is a greedy approach. This happens with other greedy algorithms: the "greey" part picks something that appears locally optimal but is not globally optimal.

2018-10-30 Dominating Set
  Def: given a graph G = (V,E), a dominating set D \subseteq V s.t. \forall v \in V\D, \exists u \in D s.t. (u,v) \in E
Problem: minimize |D|. Not the same as vertex cover: for a fully-connected graph, minimum dominating set is has one element but vertex cover has all nodes but one
  Problem is NP-COMPLETE
  ILP solution:
  D = {x_i|1 if x_i in D, 0 otherwise}
  min(sum(i,1...n,x_i))
  x_i + sum(j,1...n,\phi_ij(x_j)) >= 1 \forall i
  
 Heuristic:
 D = {}
 U = V #uncovered nodes
 while U != {}:
  Choose v \in U
  D = D + v
  U = U\(V \cup N(v)) #N(v) is all the neighbors of v
 return D
Error  bound: |D| <= (ln(\delta) + 2) * OPTIMAL_SOLN

Stener Tree Problem
  Def given a weighted graph G = (V,E), w:E->\mathbb{R}+, and a set S \subseteq V
 Find a set of edges E' \in E s.t. G' = (V',E') is connected,S is connected, and E' has minimum cost
 Special cases:
  1. When S=V, we have the minimum spanning tree problem
  2. When |S| = 2, we have the shortest-path problem
  Anything in between is APX-HARD, which means that finding an approximated solution with factor c is NP-HARD for every c > 1

Def Given G the metric ompletion G^c i a graph with the same nodes and an edge (i,J) \foreach i,j \in V and u(i,j) = length of the shortest path between i,j in G
Thm: Given a Stener tree T that spans the nodes in S in G^c, that costs w(T), there is a Stener tree in G has cost <= w(T)
Heuristic:
  Build G^c
  Consider subgraph G^c_S
  find min. spanning tree of (MST) of G^c_S
  return the union of the paths in MST
  
  Has 2-approx bound

Travelling Salesman Problem
 Def: given a undirected graph G = (V,E) and a node V, find a path that starts at v, visits all nodes once, returns to v and has minimum weight.
 
 ILP solution:
 vertices are labeled 1 to n
 x_ij: 1 if from i -> j
 d_ij: distance from i to j
 
 min(sum(i,1...n,sum(j,1...n except i,x_ij * d_ij)))
 sum(j,1...n,x_ij)=1 \forall i
 sum(i,1...n,x_ij)=1 \forall j
 x_ij=1: u_i - u_j  <= n-1
 x_ij=0: u_i - u_j <= -1

Nearest Neighbor
  1. Start from 1
  2. Pick closest node not on the path yet
  3. Move it there and goto 2
  <= 0.5 * ceil(log2(n)) * OPTIMUM_SOLUTION
